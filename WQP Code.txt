import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
import joblib  # Import the joblib library
import os
import requests
import seaborn as sns
import matplotlib.pyplot as plt

# Define the URL where the dataset is hosted
dataset_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"

# Define the local filename to save the dataset
local_filename = "winequality-red.csv"

# Check if the dataset file already exists; if not, download it
if not os.path.exists(local_filename):
    response = requests.get(dataset_url)
    if response.status_code == 200:
        with open(local_filename, 'wb') as file:
            file.write(response.content)
        print("Dataset downloaded successfully!")

# Load the red wine quality dataset
column_names = ["fixed acidity", "volatile acidity", "citric acid", "residual sugar",
                "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",
                "pH", "sulphates", "alcohol", "quality"]
wine_data = pd.read_csv(local_filename, sep=";", names=column_names, skiprows=1)

# Data Exploration and Visualization
# Group the data by wine quality and calculate mean values
quality_means = wine_data.groupby('quality').mean()
print("Mean Values by Wine Quality:\n", quality_means)

# Visualize the distribution of wine quality
sns.countplot(wine_data['quality'])
plt.xlabel('Wine Quality')
plt.ylabel('Count')
plt.title('Distribution of Wine Quality')
plt.show()

# Feature Selection (if needed)
# Identify the most relevant features
selected_features = ["fixed acidity", "volatile acidity", "citric acid", "residual sugar",
                     "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",
                     "pH", "sulphates", "alcohol"]

# Data Preprocessing (if needed)
# Keep only the selected features
wine_data = wine_data[selected_features + ["quality"]]

# Data Splitting
X = wine_data.drop(["quality"], axis=1)  # Remove the target column 'quality'
Y = wine_data["quality"]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Model Development (Random Forest Regressor with hyperparameter tuning) - Example
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    # Add other hyperparameters to tune
}

grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5)
grid_search.fit(X_train, Y_train)
rf_regressor = grid_search.best_estimator_

# Model Evaluation
Y_pred = rf_regressor.predict(X_test)
# Evaluation metrics for regression problem
mae = mean_absolute_error(Y_test, Y_pred)
mse = mean_squared_error(Y_test, Y_pred)
rmse = np.sqrt(mse)

print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Model Visualization (Feature Importance)
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': rf_regressor.feature_importances_})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance)
plt.title('Feature Importance')
plt.show()

# Save the trained model
model_filename = 'wine_quality_model.pkl'  # Define a filename to save the model
joblib.dump(rf_regressor, model_filename)  # Use joblib.dump() to save the model
print(f"Trained model saved as {model_filename}")

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

# Load the trained model
model_filename = 'wine_quality_model.pkl'
loaded_model = joblib.load(model_filename)

# Load the dataset
column_names = ["fixed acidity", "volatile acidity", "citric acid", "residual sugar",
                "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",
                "pH", "sulphates", "alcohol", "quality"]
wine_data = pd.read_csv("winequality-red.csv", names=column_names, header=0, sep=';')

# Define a function for making predictions with user-friendly input
def predict_wine_quality():
    user_input = {}
    print("Please provide the following information about the wine:")

    for column in column_names[:-1]:  # Exclude the 'quality' column
        while True:
            try:
                value = float(input(f"Enter {column}: "))
                user_input[column] = [value]
                break
            except ValueError:
                print("Invalid input. Please enter a numeric value.")

    input_data = pd.DataFrame(user_input, index=[0])
    prediction = loaded_model.predict(input_data)

    # Map the prediction to a quality description
    quality_description = "Poor" if prediction[0] < 5 else "Average" if prediction[0] < 7 else "Excellent"

    print(f"\n*** Predicted Wine Quality: {prediction[0]:.2f} ({quality_description}) ***")

# Make predictions with user-friendly input
predict_wine_quality()
